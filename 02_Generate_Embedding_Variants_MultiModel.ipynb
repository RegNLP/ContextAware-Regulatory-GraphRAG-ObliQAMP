{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1WjaHGHsleVgwSydxWlQAITz4MlZZuONh",
      "authorship_tag": "ABX9TyMmfCk+oCwIkzMXNOWwRzMr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RegNLP/ContextAware-Regulatory-GraphRAG-ObliQAMP/blob/main/02_Generate_Embedding_Variants_MultiModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZuKmg6t0TNZ"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 02_Generate_Embeddings_with_Advanced_Models.ipynb\n",
        "#\n",
        "# Purpose:\n",
        "# 1. Load both fine-tuned and pre-trained retriever models.\n",
        "# 2. Apply instruction prefixes where necessary for models like e5 and bge.\n",
        "# 3. Generate a new, high-quality set of passage embeddings for each model\n",
        "#    and context strategy for a full comparison.\n",
        "# ==============================================================================\n",
        "\n",
        "# !pip install -q -U sentence-transformers transformers networkx\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Config ---\n",
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/RIRAG-MultiPassage-NLLP/\"\n",
        "GRAPH_PATH = os.path.join(BASE_PATH, \"graph.gpickle\")\n",
        "# Point to the folder where your new fine-tuned models are saved\n",
        "FINETUNED_RETRIEVER_FOLDER = os.path.join(BASE_PATH, \"fine_tuned_retrievers_advanced\")\n",
        "# Save new embeddings to a new folder to avoid overwriting old results\n",
        "OUTPUT_FOLDER = os.path.join(BASE_PATH, \"embeddings_advanced\")\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# --- Load Graph ---\n",
        "print(\"Loading graph...\")\n",
        "with open(GRAPH_PATH, \"rb\") as f:\n",
        "    G = pickle.load(f)\n",
        "print(\"Graph loaded successfully.\")\n",
        "\n",
        "# --- Models to Use for Embedding ---\n",
        "# Includes both the new advanced fine-tuned models and their pre-trained originals\n",
        "MODELS_TO_USE = {\n",
        "    \"e5-large-v2_FT_Advanced\": os.path.join(FINETUNED_RETRIEVER_FOLDER, \"e5-large-v2\"),\n",
        "    \"all-mpnet-base-v2_FT_Advanced\": os.path.join(FINETUNED_RETRIEVER_FOLDER, \"all-mpnet-base-v2\"),\n",
        "    \"bge-base-en-v1.5_FT_Advanced\": os.path.join(FINETUNED_RETRIEVER_FOLDER, \"bge-base-en-v1.5\"),\n",
        "    \"e5-large-v2_Pretrained\": \"intfloat/e5-large-v2\",\n",
        "    \"all-mpnet-base-v2_Pretrained\": \"sentence-transformers/all-mpnet-base-v2\",\n",
        "    \"bge-base-en-v1.5_Pretrained\": \"BAAI/bge-base-en-v1.5\",\n",
        "}\n",
        "\n",
        "# --- Neighbor Configurations ---\n",
        "neighbor_configs = {\n",
        "    \"passage_only\": lambda G, node: [],\n",
        "    \"parent\": lambda G, node: list(G.predecessors(node)),\n",
        "    \"parent_child\": lambda G, node: list(G.predecessors(node)) + list(G.successors(node)),\n",
        "    \"full_neighborhood\": lambda G, node: list(nx.neighbors(G, node))\n",
        "}\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def add_instruction(text, model_key):\n",
        "    # Only add \"passage: \" prefix for e5 models, as BGE does not require it for passages\n",
        "    if \"e5\" in model_key:\n",
        "        return f\"passage: {text}\"\n",
        "    return text\n",
        "\n",
        "def build_contextual_text(G, node_id, get_neighbors_func, model_key):\n",
        "    \"\"\"\n",
        "    Constructs the text for embedding, applying instruction prefixes.\n",
        "    \"\"\"\n",
        "    # Get the base text and apply instruction\n",
        "    base_text = G.nodes[node_id].get(\"text\", \"\")\n",
        "    instructed_base_text = add_instruction(base_text, model_key)\n",
        "\n",
        "    context_parts = [instructed_base_text]\n",
        "    neighbors = get_neighbors_func(G, node_id)\n",
        "    for neighbor_id in neighbors:\n",
        "        context_text = G.nodes[neighbor_id].get(\"text\", \"\")\n",
        "        if context_text:\n",
        "            # Apply instruction to neighbor text as well\n",
        "            instructed_context = add_instruction(context_text, model_key)\n",
        "            context_parts.append(instructed_context)\n",
        "\n",
        "    return \"\\n\".join(context_parts)\n",
        "\n",
        "# --- Run All Combinations ---\n",
        "for model_key, model_path in MODELS_TO_USE.items():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"--- Loading Model: {model_key} from {model_path} ---\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    try:\n",
        "        model = SentenceTransformer(model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not load model {model_key}. Skipping. Error: {e}\")\n",
        "        continue\n",
        "\n",
        "    for config_key, get_neighbors in neighbor_configs.items():\n",
        "        print(f\"\\nüîç Generating embeddings: Model={model_key}, Context={config_key}\")\n",
        "\n",
        "        out_dir = os.path.join(OUTPUT_FOLDER, model_key, config_key)\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "        texts_to_encode, uids_to_save = [], []\n",
        "\n",
        "        print(\"Preparing texts from graph nodes...\")\n",
        "        for node_id in tqdm(G.nodes, desc=\"Finding Passages\"):\n",
        "            if G.nodes[node_id].get(\"type\") == \"Passage\":\n",
        "                full_text = build_contextual_text(G, node_id, get_neighbors, model_key)\n",
        "                texts_to_encode.append(full_text)\n",
        "                uids_to_save.append(node_id)\n",
        "\n",
        "        if not texts_to_encode:\n",
        "            print(\"‚ö†Ô∏è Warning: No passages found to embed. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Found {len(texts_to_encode)} passages to embed.\")\n",
        "        embeddings = model.encode(texts_to_encode, show_progress_bar=True, batch_size=32)\n",
        "\n",
        "        # Save the generated embeddings and corresponding UIDs\n",
        "        with open(os.path.join(out_dir, \"passage_ids.json\"), \"w\") as f:\n",
        "            json.dump(uids_to_save, f)\n",
        "        with open(os.path.join(out_dir, \"embeddings.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(embeddings, f)\n",
        "\n",
        "        print(f\"‚úÖ Saved: {out_dir}\")\n",
        "\n",
        "print(\"\\nAll embedding generation tasks are complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Import up sound alert dependencies\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def allDone():\n",
        "  #display(Audio(url='https://www.myinstants.com/media/sounds/anime-wow-sound-effect.mp3', autoplay=True))\n",
        "  display(Audio(url='https://www.myinstants.com/media/sounds/money-soundfx.mp3', autoplay=True))\n",
        "## Insert whatever audio file you want above\n",
        "\n",
        "allDone()"
      ],
      "metadata": {
        "id": "3oQFsL2JIKij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}